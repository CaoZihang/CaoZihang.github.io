---
layout:       post
title:        "【阅】本周阅读摘选2023-01-30 → 2023-2-05"
author:       "Cao Zihang"
header-style: text
catalog:      true
status:		  Done
mathjax: 	true
tags:
    - 日常
    - 可视化
    - 推荐系统
    - 数智化营销
    - 市场调研
---

# <center><font color="#3879B1">本周阅读摘选</font></center>

<center>2023-01-30 → 2023-2-05</center>

**目录**

[toc]

# 学术相关

## [Coggle数据科学推荐系统系列1：深入理解YouTube推荐系统算法](https://mp.weixin.qq.com/s/efpcnAZwxa4V242tJHvHtw)

​		作者梳理了2008年~2016年YouTube发表的四篇推荐系统论文，重点对2016年的YouTube深度神经网络推荐模型进行了简要介绍。

- 2008：《Video Suggestion and Discovery for YouTube》[^4]
  - 吸附算法（ADSORPTION）：解决视频标签的扩散
- 2010：《The YouTube Video Recommendation System》[^5]
  - 当时YouTube推荐系统的核心是基于Item-CF的协同过滤算法
    - 通过当前和历史兴趣中喜欢的视频找出相关视频
    - 视频相关性：共同点击个数描述
- 2013：《Label Partitioning For Sublinear Ranking》[^6]
  - 将推荐问题变成多分类问题
- 2016：《Deep Neural Networks for YouTube Recommendations》[^7]
  - YouTube迈向了以深度学习算法为主导的推荐系统

2016年的论文中认为YouTube构建推荐系统面临的三大难点是：

- 数据规模庞大：用户和视频量级都是Billion级别，需要分布式学习算法和高效部署
- 即时响应：推荐系统需要实时对新视频和用户新行为做出响应
- 数据噪声强：大部分视频只有隐式反馈（用户对视频的观看行为），缺少显示反馈（评价）；视频meta信息结构化程度有限；数据稀疏；易受外部因素影响

### 系统框架

![图片](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/w2-8-1)

- **第一部分 召回网络**
  - 从百万级数据库中检索少量候选视频
    - 快速处理：模型和特征不能过于复杂
  - 依据用户的历史信息召回
  - 用户相似度通过粗略特征表示

- **第二部分 排序网络**
  - 丰富和精细用户/视频特征
  - 预测用户对召回视频的评分，排序
  - 需要精准推送视频，采用复杂模型和特征提升推荐效果
- **第三部分 线下评估**
  - 评价指标：precision、recall、ranking loss
  - 线下A/B Test：点击率、观看时间等

### 召回网络

**传统召回思路**

1. 离线计算商品的Embedding和用户的Embedding
2. 线上召回：用户Embedding和商品Embedding内积，找出TOP N

存在问题：性能问题、计算问题等

**YouTube召回模型**

​		召回阶段，YouTube将推荐问题视作超大规模多分类问题（Softmax分类）

​		即基于特定用户$U$及其上下文$C$，在时间$t$被观看的特定视频$w_t$为视频库$V$中的数百万视频$i$（类）的概率：$P(w_t=i\|U,C)=\frac{e^{v_iu}}{\sum\limits_{j\in V}e^{v_ju}}$

​		其中$u\in\mathbb{R}^N$表示（用户，上下文）对的高维嵌入Embedding向量，$v_j\in \mathbb{R}^N$表示每个候选视频的Embedding向量。在这里Embedding只是简单的将稀疏实体映射到稠密向量之中。

​		学习器的任务是学习（用户历史信息，上下文）的函数user embeddings向量$u$，使之能够作为$w_t$的Softmax有效分类。

​		为提高训练效率，YouTube采用了负采样算法（“候选人抽样”）提升训练速度，并用重要性加权方式校正采样。之后为每个样本，对其真实标签和负类最小化交叉熵损失函数。根据测试，该方式比经典Softmax速度提升超过100倍。

**YouTube召回模型网络结构**

​		受NLP任务采用word2vec将文本表示成计算机可理解的结构启发，采用了word embedding的技巧将视频嵌入到固定长度的高维向量中并喂给前馈神经网络。用户的观看历史表示为由稀疏的视频ID通过Embedding映射到稠密向量的变长序列。DNN网络需要固定大小的稠密输入所有对几个嵌入表现最好的策略（求和、Component-wise max等）简单求平均。

![image-20230210164432728](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/w2-8-dnn-2)

​		使用DNN的重要原因是模型可以轻松输入连续型变量和分类变量，如用户地理信息、设别、性别、年龄等，其中登录状态和年龄进行了归一化。

**特征工程**

​		这篇论文中的一项重要特征工程是样本年龄Example Age，即用户倾向于观看新的视频（即便会牺牲一些相关性），而传统的模型都是基于历史观看记录计算的，这违背了现实。实验表明，Example Age对模型拟合提升效果十分明显。

> 一个十分经典、明晰的消费者行为

![图片](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/w2-8-DNN-3)

​		MLP层是常见的塔状设计，底层最宽，往上每层神经元数据减半，及至Softmax层是256维，激活函数采用ReLU。

**召回优化**

​		目前，我们获取了所有视频的Embedding $k$维向量$v_j, j\in V$，维度是$pool\ size\times k$，用户$k$维输出向量$u$。

​		在线服务阶段，系统通过对视频向量$v_j$和用户向量$u$进行相似度计算。此处，为满足时延要求，实际采用的是最近邻查询方式提取TOP N视频作为召回结果。

**样本选择和上下文选择**

- 使用更广的数据源：推荐场景数据+搜索场景数据等

- 为每个用户生成固定数量训练样本：平等对待每个用户，避免loss被少数活跃用户掌控

- 抛弃序列信息：对Embedding向量进行加权平均，这有些反直觉，可能是模型对负反馈没有很好建模

- 不对称的共同浏览问题（asymmetric co-watch）：传统协同过滤算法采用上下文信息的held-out模式，而A/B测试中使用上文信息的predicting next watch模式更佳

  ![图片](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/w2-8-DNN-4)

### 排序网络

​		在排序阶段，主要目的是对候选集进行细化和校准，同时还涉及多种不同召回源视频的有效集成。此外，由于候选集规模较小，所以排序阶段可以进行更精细化的建模。

**特征工程**

​		虽然深度学习中隐含了特征工程，但YouTube认为数据的类型不适合前馈神经网络的输入， 所以还是进行了特征工程。

- 用户历史行为：与哪些items有过交互或和相似的items有过交互
- 上次观看时间：自上次观看同channel视频的时间
- 视频曝光次数：若视频已经曝光给该用户且没有观看，则下次曝光被观看的概率降低
- 视频提名来源、得分

​		对于分类特征，使用Embedding将稀疏的特征映射到适合神经网络的稠密矩阵形式。每个独特视频ID对应一个单独学习的Embedding向量，它的维度和ID个数的对数成正比。我们将大的候选集裁剪为仅包含点击印象最高的TOP N个视频，其他视频被嵌入为0。视频ID的分类特征底层Embedding是共享的，对提升泛化能力、加速训练、减小内存非常重要。

​		对连续特征，YouTube团队使用了归一化减少神经网络对输入的缩放和分布敏感问题的影响。连续型特征的分布$f$被转化为[0,1)均匀分布。此外，作者还输入了这些特征的超线性（$\bar{x}^2$等）和亚线性（$\sqrt{\bar{x}}$等），使非线性关系更容易在神经网络中被表达，增强了拟合效果。

**排序模型**

​		排序模型的训练目标是预测正例（点击）和负例（未点击）的用户观看时长，这样可以排除用户点击但不愿意看这类情况的噪声。模型采用加权logistic回归，损失函数为交叉熵损失。其中正例采用观看时长作为权重，负例使用单位权重，这样logistic回归学得的odds为$\frac{\sum T_i}{N-k}$，其中$N$为训练样本数，$k$为正例数，$T_i$为第$i$个视频的观看时长。假设正例在样本中很小（实际中，推荐的视频是相对多的，而用户只能点击一个），则odds就近似为$E(T)$，之后使用指数函数作为最终的激活函数产生观看时长的近似值。

**隐藏层设计**

![image-20230210200030790](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/W2-8-DNN-5)

​		YouTube借助次日测试数据在实际环境中测试了不同隐藏层配置。其中weighted, per-user loss是通过向用户展示的同一页面推荐视频的模型打分里负例得分高于正例的比例计算获得的。结果表示隐藏层网络宽度和深度增加都能提升模型效果，但也增大了CPU时间开销，权衡后最底层为1024 ReLU。

![image-20230210180248236](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/w2-8-DNN-6)

## [机器学习百道面经](https://mp.weixin.qq.com/s/eudpG82cy1BntH9sW5K_iw)

​		关于聚类、正则化、损失函数等问题的面试题，转存

​		本地存储位置：''./My_job/机器学习百道面经.md'

## [高效整数规划求解，快手提出多元因果森林模型，智能营销效果显著](https://baijiahao.baidu.com/s?id=1727362250756632494&wfr=spider&for=pc)

​		快手为了实施细粒度的营销决策，在因果森林的基础上提出了多元因果模型，使单一模型可以同时处理多种干预手段，而不是仅仅是二元因果。

​		首先归回到目前业界希望借助因果推断解决的核心问题之一——异质性因果效应HTE。HTE是指由于样本个体特征不同，干预在个体上产生不同效果的现象。在精准营销之中，精确地区分不同干预的目标受众和影响是一项至关重要的工作。

​		近年来学界业界比较认可的HTE方法是Stanford经济学教授Susan Athey et al.提出的因果森林模型GRF[^1]（[代码](https://grf-labs.github.io/grf/)）。GRF引入了得分函数$\Psi(O_i)$，待拟合函数$\theta(x)$和辅助函数$v(x)$，其中$o_i$是$(Y_i,W_i)$。算法的核心是寻求满足局部估计等式$E[\Psi_{\theta(x),v(x)(O_i)\|X_i=x}]=0, for\ all\ x\in X$，对因果效应估计$\Psi_{\theta(x),v(x)(o_i)}=Y_i-\theta(x)W_i-v(x)$，对应$Y=\theta(x)W_i+v(x)$通过学习$\theta(x)$使得实验组和空白组数据预估值和真实值差异最小。在无混淆假设下$\theta(x)=\frac{Cov[W_i,Y_i\|X_i=x]}{var[W_i\|X_i=x]}$。[^2]

​		GRF本质是基于CART树的随机森林。最大化分裂标准$\bigtriangleup(C1,c2)=\frac{n_{c1}n_{c2}}{n_p^2}(\hat{\theta}_{c1}(J)-\hat{\theta}_{c2}(J))^2$。后边暂时没看明白，以后拿原始论文再看一下。

​		快手的多元因果森林模型[^3]（[代码](https://github.com/www2022paper/WWW-2022-PAPER-SUPPLEMENTARY-MATERIALS)）重新设计了因果森林的分裂准则，每次分裂时不但强调不同节点间的异质性，即节点间分裂，同时也强调节点内不同干预手段的异质性，即节点内分裂。

​		为平衡算法的效率和效果，该模型首先通过节点间选择TOP N个备选特征分裂点；之后通过节点内分裂从N个备选中选择最终的特征分裂点。此外，在快手亿级别的用户量导致决策变量数极大的环境下，使用现存的开源求解器会出现内存溢出等问题，所以快手团队设计了可并行的Dual Gradient Bisection(DGB)算法，运用了松弛、KKT和对偶等方法对问题进行转换。

​		在多元因果模型评估上团队没有很好的解决思路。目前在二元因果模型中，常用的评估方法是AUUC、Qini Curve等，若使用其评估多元因果模型需要把模型拆分为二元因果，而这样就丧失了多元因果的价值了。

​		目前团队使用的一个评估方法是利用随机控制实验数据构建可以观测真实结果的匹配样本。这些匹配样本的均值是各列期望的良好估计，所以可以计算多元因果模型的整体收益。

​		最后，团队通过WWW 2021的公开仿真数据集与业界主流树基因果模型进行对比，多元因果森林效果优于CT.ST和CF.DT。实际部署在快手智能营销的AB实验的效果也比较好。

![img](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/6159252dd42a2834788395cc3286c1e014ceb)

# 业界动态

## [Hanover Research： The State of Market Research](https://mp.weixin.qq.com/s/GhWO-8XUM51fyJ4HoC8TjQ)

> **以数据为依据的慎重投资获得了回报：依赖市场研究的公司比那些不依赖市场研究的公司更有可能增加销售额、扩大市场并提高客户保留率，多数商业领袖预计增加市场调研预算**

**利益关联：该报告由美国市场调研公司撰写**

调研问题：美国商业领袖如何使用市场研究增加销售额，留存客户并扩大市场份额，进而实现投资回报率ROI的增长？

调研背景：在三年疫情的冲击下，美国商业领袖们经历了劳动力短缺、供应链反应迟钝等问题，这些要求企业必须快速适应环境并及时做出反应。如今，在冲击的余波下，具有前瞻性的企业已经从救火模式转变成扩张性的增长策略。因此，如何选择正确扩张领域，获取ROI是这些企业目前面临的棘手问题

调研对象：399家美国商业领袖企业的管理层员工，其中322家采取了市场调研行动（79%），77家没有

调研方法：线上问卷（质性）+第三方卖方专家小组+受访者资质审查

调研发现：95%的企业（n=255）通过市场调研获取正的ROI；91%的企业（n=118)认为市场调研增加了销售额；89%的企业（n=122）认为市场调研增加了客户留存率；69%的企业（n=399)计划在2023年追加市场调研预算

> 调研人员没有解释样本大小不一问题

调研结论：使用数据导向市场调研的企业比其他企业更可能增加销售额、扩大市场份额并提高客户留存率

- 市场调研有助于解决企业目前面临的主要挑战![image-20230211005348803](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/image-20230211005348803.png)

  > 未解释两边样本不平衡问题，有操纵数据嫌疑

- 相比没有采取市场调研问题的企业，采取市场调研的企业在销售额增长、增加客户留存、新产品/服务发售、进入新市场、进入临近市场的表现都更优

  > 相关关系不是因果关系，可能存在严重内生性问题，结论不可靠

- 总的来说，多数企业认可市场调研具有三项好处

  - 深入理解市场
  - 识别机会
  - 揭露风险

​		256家企业分享了它们在2022年的市场调研频率，其中多数开展了1~10项市场调研。

> 同样，研究人员没有说明剩余的66家企业的情况，但对结论影响有限

![image-20230211010807528](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/image-20230211010807528.png)

|                   61%的企业开展了市场调研                    |               59%的企业开展了产品生命周期调研                |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| 市场进入策略<br>市场份额识别<br>竞争分析<br>市场细分<br>市场趋势分析<br>并购机会 | 产品生命周期管理<br>产品研发<br>产品组合评审<br>包装设计<br>定价策略<br>渠道战略<br>销量预测 |
|              **58%的企业开展了消费者体验调研**               |               **55%的企业开展了品牌战略调研**                |
| 用户画像<br>消费者细分<br>消费者旅程<br>购买路径<br>消费者决策过程<br>消费者需求评估<br>消费者聆听 | 品牌资产<br>品牌知名度<br>品牌感知<br>品牌跟踪<br>品牌发展与定位<br>品牌重塑<br>内容营销开发 |

**调研手段**

- 数据分析和建模——68%
- 问卷调查——63%
- 二手数据研究——55%
- 焦点小组——51%
- 购买辛迪加数据——48%
- 深度访谈——40%

现有企业调研项目频率与调研项目价值的关系图

![image-20230211132224865](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/202302111341442.png)



# 技术技巧

## Python库：plottable高度个性化表格

[github](https://github.com/znstrider/plottable)

[帮助文档](https://plottable.readthedocs.io/en/latest/example_notebooks/bohndesliga_table.html)

![../_images/e8d1fbc8adad079e0f4b9854873506539bd580747d14f617ec24b9eb329aea87.png](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/e8d1fbc8adad079e0f4b9854873506539bd580747d14f617ec24b9eb329aea87.png)

## Python库：pynimate动态条形图

[github](https://github.com/julkaar9/pynimate)

[帮助文档](https://julkaar9.github.io/pynimate/)

![img](https://raw.githubusercontent.com/CaoZihang/picpicpicpicpicpic78k664/main/img/examw2-8ple3.gif)

[案例](https://mp.weixin.qq.com/s/ixRpMAsJ1CgltjEGw7nWmQ)

[^1]: Athey, S., Tibshirani, J., & Wager, S. (2019). Generalized random forests. *The Annals of Statistics*, *47*(2). https://doi.org/10.1214/18-AOS1709
[^2]: https://zhuanlan.zhihu.com/p/397546177
[^3]:  Ai, M., Li, B., Gong, H., Yu, Q., Xue, S., Zhang, Y., Zhang, Y., & Jiang, P. (2022). LBCF: A Large-Scale Budget-Constrained Causal Forest Algorithm. *Proceedings of the ACM Web Conference 2022*, 2310–2319. https://doi.org/10.1145/3485447.3512103
[^4]: Baluja, S., Seth, R., Sivakumar, D., Jing, Y., Yagnik, J., Kumar, S., Ravichandran, D., & Aly, M. (2008). Video suggestion and discovery for youtube: Taking random walks through the view graph. *Proceedings of the 17th International Conference on World Wide Web*, 895–904. https://doi.org/10.1145/1367497.1367618
[^5]: Davidson, J., Liebald, B., Liu, J., Nandy, P., Van Vleet, T., Gargi, U., Gupta, S., He, Y., Lambert, M., Livingston, B., & Sampath, D. (2010). The YouTube video recommendation system. *Proceedings of the Fourth ACM Conference on Recommender Systems*, 293–296. https://doi.org/10.1145/1864708.1864770
[^6]: Weston, J., Makadia, A., & Yee, H. (2013). Label Partitioning For Sublinear Ranking. *Proceedings of the 30th International Conference on Machine Learning*, 181–189. https://proceedings.mlr.press/v28/weston13.html
[^7]: Covington, P., Adams, J., & Sargin, E. (2016). Deep Neural Networks for YouTube Recommendations. *Proceedings of the 10th ACM Conference on Recommender Systems*, 191–198. https://doi.org/10.1145/2959100.2959190
