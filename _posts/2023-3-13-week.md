---
layout:       post
title:        "【阅】本周阅读摘选2023-03-06 → 2023-3-12"
author:       "Cao Zihang"
header-style: text
catalog:      true
status:		  Done
mathjax: 	true
tags:
    - 日常

---

# <center><font color="#3879B1">本周阅读摘选</font></center>

<center>2023-03-06 → 2023-3-12</center>

**目录**

[toc]

# 学术相关

## 数智化新产品开发平台[^1]

目前已有文献对数智化的讨论还是比较粗糙和保守，总觉得未来还是应该有一些颠覆性的东西。

![image-20230417224359753](https://img.czhread.asia/img/202304172250369.png)

## [ InstructGPT 标注：数据是关键](https://mp.weixin.qq.com/s/b9QnMtHj6yJfN0goBRSCXg)

终于看到一篇讲GPT数据标注的文章了。

ChatGPT同期发布的姊妹模型InstructGPT拥有公开的标注指南。

GPT在第一步有监督微调supervised fine-tuning（对样本Prompt编写人工答案）和第二步奖励模型reward model（输出排序）中需要标注数据。这要求对标注人员有较高的规范标注。

### 标注数据

OpenAI数据来源主要包括两个

- OpenAI API提交的Prompt
  - playground用户使用数据
    - 去除重复Prompt
    - 每个用户最多200个Prompt——保证数据多样性
    - 基于ID划分训练集、验证集、测试集
- 标注人员编写的Prompt
  - Plain：随便想任务
  - Few-Shot：给出一个Instruction，编写多个$(query,response)$对
  - User-based：根据OpenAI API的候补名单用例，编写Prompt![efwee](https://img.czhread.asia/img/202304181135297.png)

所有的Prompt最终形成3个数据集

- SFT数据集
  - 包含API和标注人员编写的13k Prompt数据集
  - 标注人员编写答案，用来训练SFT模型
- RM数据集
  - 包含API和标注人员编写的33k Prompt数据集
  - 标注人员排序模型输出，用来训练RM
- PPO数据集
  - 仅包含API的31k Prompt数据集
  - 没有标注，用作RLHF微调的输入

![erewr](https://img.czhread.asia/img/202304181139717.png)

![tytrhrtyh](https://img.czhread.asia/img/202304181148229.png)

### 标注人员

目前业内数据标注流形的是众包模式，标注人员水平参差不齐。

InstructGPT的任务目标是选择一组对不同人口群体的偏好敏感，并且善于识别潜在有害输出的标注人员。

筛选标注

- 对敏感言论标注的一致性
- 对排序的一致性
- 敏感Prompted答案撰写
  - 使用7级Likert量表对答案评级
- 自我评估识别不同群体敏感言论的能力
  - 「对于哪些主题或文化群体，您可以轻松地识别敏感言论？」

InstructGPT标注人员特征：数据源自自愿匿名调查

- 整体男女比例相当
- 大部分年龄在35岁以下
- 本科学历占一半以上
- 东南亚地区标注人员占一半以上![32-df](https://img.czhread.asia/img/202304181159282.png)

标注人员统一UI

![fefwef](https://img.czhread.asia/img/202304181201975.png)

### 标注规范

InstructGPT设置了3个考量指标评估模型的输出

- 有帮助helpful
- 真实性truthfulness
- 无害性harmlessness

指标权衡方案的指导方针包括无害和真实比有帮助更重要；但若任务不属于高风险领域则提高有帮助指标权重等。

Instruction属性标注，检查是否包含个人敏感信息、道德问题等。

**模型输出标注**包含多个项目

- 评分（7级Likert）
- 是否遵循了指示
- 回答是否得当（将LLMs视作助理客服）
- 是否幻觉

**输出排序标注**

**有毒输出标注**

- 毒性
  - 0分：输入/输出完全无毒
  - 1分：输入/输出轻微毒性，或被部分人认为有毒
  - 2分：明确有毒
- 相对毒性
  - -1分：输出的毒性比预期低
  - 0分：与预期一致
  - 1分：比预期更严重
- 连续性
  - 输出是输入文本的合理延续
  - 7分Likert

## [基于Bass模型的单条推特的流行性预测框架](https://mp.weixin.qq.com/s/PZ9kDI_H7DUNXRNqoMVCew)[^2]



## [Python: MCMC与睡眠数据](https://mp.weixin.qq.com/s/NTcCSUXN_DsZ-_OJ5LkfHA)



## [简便关联：灰色关联分析GRA](https://mp.weixin.qq.com/s/uHdQ-yQwad4mLLC3ZlB71w)

基本思想：根据序列曲线几何形状的相似度判断关联是否紧密

- 支持小样本
- 主观性强，国际认可有限

计算很简便，但GDP的示例数据表现甚至不如简单的线性回归

或许有一些离群值会表现好一些？

# 业界动态

## [如何衡量和分配广告渠道？](https://mp.weixin.qq.com/s/W3SejtPrM--5wkkMxUKZpw)



[^1]: 曾伏娥龚政 &amp; 郭逸鸿. (2023). 数智化新产品开发平台. 营销科学学报, *3*(60–77).

[^2]: Gao, X., Zheng, Z., Chu, Q., Tang, S., Chen, G., & Deng, Q. (2020). Popularity Prediction for Single Tweet based on Heterogeneous Bass Model. *IEEE Transactions on Knowledge and Data Engineering*, 1–1. https://doi.org/10.1109/TKDE.2019.2952856



