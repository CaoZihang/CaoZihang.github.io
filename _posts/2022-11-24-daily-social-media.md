---
layout:       post
title:        "【日常】与朋友交流：研究的客观理性与社交媒体三则研究"
author:       "Cao Zihang"
header-style: text
catalog:      true
status:		  Done
tags:
    - 研究方法
    - 日常
---

‌‌‌	朋友提出了一个如何在研究中保持客观理性的问题，颇有意思，就一起多讨论了一下，顺带着交流了几个有趣的研究，略作心理安慰。考虑到朋友是学外语的，所以很多内容都进行了简化以便于理解。

​	聊的内容不少，故秉持着尽可能不浪费的思路把聊天内容进行了简单梳理，在网页里滥竽充数。

# 一、如何在研究中保持客观理性？
## （一）人类无法形成客观理性的认知

‌‌‌　　首先，我只能先泼一盆冷水，人类目前没有方法形成客观理性的认知，所有人都一样。如果我们真的能够找到一个客观理性的认知的话，世界上就不会有这么多争议和社会问题了，实现了弗朗西斯·福山的“历史的终结”，但结论显然是不可能的，Fukuyama如今也转向了“身份政治”。
‌‌‌　　![|400](https://img.czhread.asia/img/%E6%BC%94%E7%BB%8E%E4%B8%8E%E5%BD%92%E7%BA%B3%E9%80%BB%E8%BE%91.png)
‌‌‌　　科学也一样是不客观的，抽象地讲，任何研究都受制于研究人员的自身背景、研究视角、方法、能力和利益等等，所有的研究提出的都是假说，而非真理。通常我们认为人类认知世界的手段主要有两种逻辑：**归纳**和**演绎**。顾名思义，归纳是从个案得出普遍性结论的抽象过程，是人类认知世界的主要手段。但不幸的是**归纳法只能证伪，不能证明**，只需要一个反例就可以证伪归纳法结论，而我们永远不能排除所有的个例。演绎逻辑是一种更复杂的思维，我们现代所讲的“科学”理论大多都是建立在演绎逻辑上的，它帮助我们从已知走向未知，将抽象的归纳进一步抽象到理论。例如数学，它是从已知的知识推导出未知的知识（数学公式），**演绎可以证明**，但必须保证演绎的前提（公理）是正确的，且演绎过程是正确的。但问题是**演绎的前提（已知的知识)通常来自归纳**，归纳未必正确，所以**演绎未必正确**，人类的认知问题无解。

‌‌‌　　*所以一个很简单有效的反驳他人观点就是**通过攻击演绎的前提推翻演绎，通过反例攻击归纳**。*

‌‌‌　　在大众意义上，人们普遍认为数理就是科学，认为社会科学不靠谱就是因为数理不够比较软，物理数学比较硬就很科学。这种观点我们称之为“物理崇拜”。但其实数字也并非中立的，所有学过统计的人都非常清楚的知道这一点，抛开所有人为的诱导性数据，人们同样无法基于数据得出客观中立的结论。举个栗子，当然是社科的，我正好在看一篇[PNAS的推送](https://mp.weixin.qq.com/s/Q7Zln8Sz3TkF0h8DxbDMbQ),讲73个专业科学研究团队基于相同的数据对$H_0$：**更多的移民减少了公众对社会政策的支持**这一假设进行检验[^1]，结果他们得出完全不一样甚至相反的结论，而且这些差异并不是由研究者自身造成的。这就意味着我们目前没有手段真正的客观认识世界，看图，同样的数据同样的问题，截然相反的答案，而且没有标准答案，谁也不知道哪个是对的，有趣吧？
‌‌‌　　![|400](https://img.czhread.asia/img/640.png)
‌‌‌　　

​	综上，**“伪·客观理性”研究的第一前提是：“不断告诉自己，自己不可能客观理性。”**

## （二）恰当的研究设计能够减少偏见

‌‌‌　　![|400](https://img.czhread.asia/img/640.jfif)
‌‌	**一个可靠的研究结论的前提是有一个可靠的研究设计**。它大致包含了**哲学基础（认识论)、理论视角、方法论和具体方法**四个部分。

---

……

……

---



## （三）预注册思想

‌‌‌　　当然，上述的手段是很正式的科学研究手段，日常生活中我们不可能用这样的方式来处理所有的问题，这样成本太高了，效率太低了。

‌‌‌　　所以，这里我给出一个简易的，能够在日常生活中处理小问题又能够尽可能的保持客观理性的小技巧。

‌‌‌　　它同样来自科学研究，叫做“预注册”。预注册是[开放科学框架](https://osf.io/)的一个重要内容。简单来说就是在进行实验（分析问题）之前，把研究方法、研究计划以及一些对研究有影响的决策如概念的定义、范围等等预先注册。后续的实验分析必须依照研究计划进行。这种方法能够有效的减少P-hacking问题。

‌‌‌　　对于我们的日常分析工作而言，其实就是**提前写好分析的程序**，数据收集的类型、范围等决策信息，最好符合MECE原则<font color='green'>{by the way 向麦肯锡的空雨伞思维等等这些框架可以多了解一下，突然发现这些好像更适合你orz其实基本思想是类似的，可以搜一下金字塔原理、6W2H、六顶思考帽之类的，网上相关信息很多}</font> 这样的方法能够让我们尽可能全面的接受信息。比如说营销管理学派的分析框架就是R-STP-MM-C，具体分为宏观环境分析PEST、微观环境分析（产业、企业、消费者）、市场细分-选择目标市场-市场定位、产品-价格-促销-渠道-战略的策略矩阵最后的实施控制。我们进行进一步分析的时候就要确定每一个部分的数据来源应该是哪些，我要包含哪些数据，数据会如何处理，目的是了解什么信息。之后再进行数据收集工作，获取所有的数据后，我们要进行第一轮分析，找到可能有战略空间的维度再一次制定需要获取哪些数据，交替往复。

‌‌‌　　另外，我个人倾向于**在第一轮资料收集工作中将收集与分析两个环节完全分离。** 因为分析会让我在无意识中有选择地收集资料。当然后续的工作应该是数据收集与分析循环递进的，我通常不会分离。



---

……

……

……

---

‌‌‌　　当然，这种想法很简单，但根据我的经验我们实际上更倾向与选择与我们预期一致的观点认为是正确的观点，预期不一致的观点是错误的观点。这种方法告诉我们的是，如果有两种观点对同一个问题进行了回答，它们都使用了可靠的数据、合理的分析程序，那么无论你支持哪种观点都应该考虑向两种观点的均值回调你的观点。

‌‌‌　　**我支持一种可以得到更接近客观分析的方法是，如果你不能在分析之中保持完全没有观点，那就尽可能地使用更多的理论视角来看问题。**
>有人做了个比喻叫做，每种观点都是有色眼镜，我们必须带上眼镜才能看清问题，但每一种眼镜看到的结果都是有色的，所以你应该尽可能的尝试一下每一种眼镜看到的结果，综合起来会更有可能接近真相。

‌‌‌　　所以说，我建议应该把**每一种观点的事实**都放在一起比较，每加入一个观点最好尽快找一个跟它不同的观点，代入每一种视角，并通过自我催眠尽可能的以旁观者态度综合分析事实，客观理性的结果通常位于多种极端观点的中间，不那么好也没有那么坏。

‌‌‌　　以上的内容只能说依据我自身的知识提出一些可行性较高，能够在短期内有一定提升的方法。但是我还是要强调目前人类没有手段能够做到真正的客观理性，只能说在日常判断中不断对自我进行审视，告诉自己：“**我的观点必然有偏见，其他人的观点也一样。**”不断修正自己的判断，螺旋式的提升自己的认识（突然马哲orz，但这一部分确实是精华）

---

……

……

---

# 二、社交媒体研究三则

‌‌‌　　**疫情防控我管不了，我只能聊聊社交媒体**，或许能对你**未来**的工作有些许帮助。我更想说一下，其实社交媒体上眼见的东西未必是真实的。

‌‌‌　　这里讲最近看到的三个研究摘要，前两个研究说的是互联网上的信息是极端的、非理性的，第三个讲的是感官其实也是情绪化的。

### 1. 社交网络机器人对观念的影响

**Detecting Bots and Assessing Their Impact in Social Networks**[^2]

​	这是2018年MIT一位教授团队进行的一项非常具有颠覆性意义的研究，他们证实了Twitter上只需要占比极少的机器人就可以极大程度的左右舆论风向，甚至可以颠覆事实。

‌‌‌　　研究背景：2016年美国大选，特朗普与希拉里

‌‌‌　　**①天才第一步：识别机器人**

‌‌‌　　他们使用了MIT团队开发的一个机器人识别算法（自引用+1），它的基本思想是找出经常转发别人的推文（传播观点），但很少被其他人@的账户（不接收观点、参与互动），这些账户的行为有较高概率是机器人账户。

‌‌‌　　同时，由于部分账户可能被误判，为了加强证据的强度，研究者把所有拥有实名认证的账户都归为真实用户。

‌‌‌　　最终，研究人员在2016年第二次选前辩论希拉里&特朗普数据集中找到了396个Twitter机器人，并对它们的言论进行语义分析，划分了260个支持特朗普的机器人和136个支持希拉里的机器人。这些机器人在数据集的用户总量中不到0.5%。
‌‌‌　　![|400](https://img.czhread.asia/img/swarma7-1541336414.jpg)

‌‌‌　　**②演绎的起点：提出假设**

‌‌‌　　量化的变量：

‌‌‌　　1. 观点的强度$\theta_{i}\in [0,1]$：0绝对支持希拉里；1绝对支持特朗普

‌‌‌　　2. 账户$i$的推文频率$\lambda_i$

‌‌‌　　构建网络舆论模型：

‌‌‌　　$$\sum\limits_{j\in friends of i} \lambda_i(\theta_{i}-\theta_j)=0$$

‌‌‌　　模型包含两个基础假设（演绎的前提)：

‌‌‌　　1. 社交网络中的个人是基于其朋友推文的观点来更新自己的观点的

‌‌‌　　2. 网络中某些用户的观点是顽固的，不容易改变，并且会推动其他用户改变观点

‌‌‌　　这个模型意味着一个用户的观点受其所有好友观点的影响，而若它的好友里存在顽固用户，非顽固用户的观点就会被顽固用户观点决定。

‌‌‌　　毫无疑问，机器人账户是顽固用户，有了这样的模型就可以假设剔除机器人账户的情况是什么样的了。

‌‌‌　　**③操控舆情分析**

‌‌‌　　基于上述模型，作者计算了四种舆情：没有机器人、只有特朗普机器人、只有希拉里机器人、包含所有机器人。
‌‌‌　　![|400](https://img.czhread.asia/img/swarma6-1541336416.jpg)
‌‌‌　　

​	数据集的初始观点在0.4到0.5之间，剔除全部机器人，模型计算的舆情是偏向特朗普多一点0.58。加入特朗普机器人后舆论就被向特朗普方向拉了0.18，到了0.76；而只加入希拉里机器人会使舆情向希拉里方向转变0.32个单位，达到0.26。

‌‌‌　　**结论1：在总数中占比不足0.5%的机器人能够很大程度的操控舆情，甚至使舆情完全转向**

​	**结论2：希拉里机器人数量低于特朗普机器人，但效果强于特朗普机器人**

‌‌‌　　**④效果差异分析**

‌‌‌　　从模型上看，结论2的原因有两种可能，一种是希拉里机器人影响力更大，有更多关注者进而影响人数更多；二是仅仅因为希拉里机器人发帖更多

‌‌‌　　首先， 猜测1很快就被证伪了，希拉里机器人和特朗普机器人在粉丝数量上没有显著差异。

‌‌‌　　之后作者对比了特朗普机器人、希拉里机器人和支持特朗普真实用户、支持特朗普真实用户的发帖频率，发现所有真实用户发帖频率基本一致，特朗普机器人频率远大于真人，希拉里机器人又远大于特朗普机器人![|400](https://img.czhread.asia/img/swarma8-1541336417.jpg)
‌‌‌　　emmm这个猜测一个简单的归纳逻辑验证成立！开始演绎！

‌‌‌　　作者将网络舆论模型中所有的参数调成相同参数，重新计算了舆情，发现：机器人没用了！
‌‌‌　　![|400](https://img.czhread.asia/img/swarma2-1541336417.jpg)
‌‌‌　　结论：占比不到0.5%的社交媒体机器人仅仅通过没完没了的发强烈倾向观点的推文就能极大地颠覆社交网络舆情。

‌‌‌　　当然这个模型其实不是很精准，特别是在建模的设计上完全缺乏质性的支持，即演绎的前提是存在较大的质疑的，而且设计的参数比较有倾向性，这个模拟不足以说明二者在实际上存在因果关系，但是模拟的结果还是挺震撼的。

### 2. 社会媒体激发两级分化

**How digital media drive affective polarization through partisan sorting**[^3]

‌‌‌　　又是一篇PNAS的文章，来自于阿姆斯特丹大学的研究。它驳斥了非常著名的信息茧房理论，指出社交媒体上的争论很可能会迫使人们全方位的凭借价值观进行站队，并不断延伸到各个方面，致使社会凝聚力崩溃。

‌‌‌　　它的研究背景是针对社交媒体导致美国近些年政治严重两极分化这一问题，传统观点信息茧房、过滤泡、回声室假说认为由于社交媒体算法的推荐导致人们接触的信息会越来越与自身同质化，最终导致每个人都处在与自己观点一致的信息茧房里，区隔开。但是这篇文章做出的贡献就是整合了互联网媒体的最新证据，推翻了这种假说，发现不同观点的人通过社交媒体上的强烈互动、冲突，导致了人们的情感极化，并且从问题立场的分歧发展到根植于身份划分的强烈对立。（与我上文提到的身份信号理论异曲同工）并且作者借助舆论动力学和数字媒体构建了一个新的解释假说。

‌‌‌　　研究结果指出，数字媒体让人们在地理空间或社交网络的局部回声室之外互动（即接触到大量不同观点）。当个人在局部进行互动时，结果是交叉冲突的稳定多元拼凑。通过鼓励非局部的互动，数字媒体促使冲突沿着党派的路线进行划分，从而消除了局部异质性的平衡作用。其结果是两极分化，即使个人互动导致了收敛。因此，该模型表明，数字媒体通过党派划分实现了两极分化，形成了一个漩涡，越来越多的身份、信仰和文化偏好被卷入一个全面的社会分裂中。

‌‌‌　　听起来可能比较复杂，举个栗子具体说明一下。疫情的观点被划分为清零派和放开派，已知两派的诉求不可能同时满足，与美国驴党、象党争夺总统问题结构相似。我们可以观察到这样的一个事实：清零、放开两派已经对彼此越来越冷淡，甚至厌恶，不断的进行彼此的攻击。

‌‌‌　　首先让我们跳出两派竞争的问题，我们可以达成的一个共识是：清零与放开通常会涉及生活的方方面面，是否要戴口罩、是否打疫苗、阳性是否可以居家、轻症要不要去医院等等这些**复杂、多元的子问题**。

‌‌‌　　在一个**局部的小范围**内，例如A群体都是主张先清零，然后待医疗物资充足后逐步放开的，他们可能对日常要不要戴口罩，让不让其他群体（外乡人）进入，阳性人员是小区隔离还是楼道隔离有争议，但是每个人对以上这好几个问题都有不同的、不重叠的观点，那么这样大家虽然在问题上有争议，但是大体方向是一致的，那么大家就可以通过互相辩论、博弈的方式实现可持续的社会冲突，能够形成一个大致可接受的局部处理方案，获取局部的满意解。

​	最终结果可能是甲地医疗资源丰富、老龄化程度低，那么就采用一个较为开放的政策，乙地医疗资源匮乏，那么政策就稍稍严格一些。无论大家怎么选择，我们都是在找对**局部利益相关者比较能够接受的一个解决方案**，如果在清零、放开的意见上不一致，但是我们可能因为喜欢同一支足球队，那么大家还是可以做朋友，互相尊重。在疫情争论上也是**摆证据、提方案**。那么这样的社会冲突就是良性的，我们国家中央给地方一定的自主决策权、美国选票制度都是基于类似这样的社会竞争设想。**即局部进行互动时，结果是交叉冲突的稳定多元拼凑。**

‌‌‌　　但社交媒体的出现改变了故事的叙事，地理和观点的局部讨论被打破，上升到**全局范围的争论**。我们每个人被暴露在各种各样的观点、各种财富、教育、利益背景的人海之中，我们面临着一场**政治战争**。依据舆论动力学模型，为了维护自身的利益，每个人都有倾向在这场战争中选择与自己观点、利益较为相似的个体进行**结盟**，形成更强的影响力和互动能力，因此我们往往会忽视防疫问题是一个复杂的、包含多元子问题的社会领域，情感发生极化，**转变为单纯的清零派、放开派二元对立分类**。这个时候，局部时关于多元子问题的良性冲突平衡失效了，人们被动无意识地会将多种冲突按照**党派路线**进行分类，从而推动了冲突的全面整合，变成高强度的二元对立，在这一过程中，**越来越多的问题被拖入一个不断增长的社会和文化鸿沟，进而推动社会凝聚力的崩溃**。二元分类导致人们为强化自我的身份信号，对对立党派采用**不信任、蔑视、质疑对方的合法性和人格甚至造假等方式来表达对立，通过极化自我的观点来宣称自己的分裂**，这样的行为又产生负反馈，进一步极化两派对立。

‌‌‌　　事实上，数字媒体不是作为回音室而是作为分拣机加剧了两极分化，导致社会进程失控，破坏了多元社会的稳定。现有的社交媒体试图通过打破信息茧房的方式解决社会割裂问题很可能是南辕北辙，甚至进一步加剧社会的割裂。


### 3. 心理台风眼效应

**汶川"5.12"地震中的"心理台风眼"效应**[^4]

‌‌‌　　这是中科院心理研究所李纾老师的一个研究，很有名。

‌‌‌　　通常来讲，我们认为一个恶性事件对人们造成的心理伤害通常是与人们离恶性事件的距离成正比的，这是一个很自然的想法，也是我们绝大多数人处理问题的一种思维方式。早年心理学上把这样的风险感知思维方式称之为“涟漪模型”。

‌‌‌　　![400](https://img.czhread.asia/img/1.jpg)

‌‌‌　　当恶性事件发生时，当事人应该受到的伤害最大，然后是他的亲人、朋友，那些借助互联网媒体了解到事件的陌生人应该受到的伤害最小甚至不会受到伤害。

‌‌‌　　但是，2008年汶川大地震后，李纾团队的调查却发现一个反直觉的现象。他们在2008年6月，向轻、中、重灾区和未受灾区域发放问卷进行调查，询问他们预期灾区恢复到灾情之前水平需要多长时间和资金。
‌‌‌　　![|400](https://img.czhread.asia/img/Snipaste_2022-11-25_12-40-18.jpg)
‌‌‌　　![|400](https://img.czhread.asia/img/2.jpg)

‌‌‌　　可以很清楚的看到未受灾群体对灾难的评估是远远高于真实受灾群体的。

‌‌‌　　通过心理台风眼效应的研究，我们可以看到**客观风险与主观风险认知并不一致。** 网上的谣言和各种虚实真假的信息实际上导致了很多人虽然不在“灾难风暴”的中心，但是可能经历了更加严重的焦虑、恐慌、愤怒和抑郁情绪；旁观者还会产生“为什么我在安然无恙地享受舒适的生活？”这样虚拟内疚，但事实上我们并没有做错任何的事。

‌‌‌　　社交媒体的出现让我们高强度的暴露在小概率的极端事件之中，往往会产生超过实际的心理焦虑，我们清楚的意识到这里面大部分事情并没有那么糟，我们的社会也没有变坏，只是我们接触到不好事件的频率变高了，感知的风险增大了。



[^1]: Breznau, N., Rinke, E. M., Wuttke, A., Nguyen, H. H. V., Adem, M., Adriaans, J., Alvarez-Benjumea, A., Andersen, H. K., Auer, D., Azevedo, F., Bahnsen, O., Balzer, D., Bauer, G., Bauer, P. C., Baumann, M., Baute, S., Benoit, V., Bernauer, J., Berning, C., … Żółtak, T. (2022). Observing many researchers using the same data and hypothesis reveals a hidden universe of uncertainty. _Proceedings of the National Academy of Sciences of the United States of America_, _119_(44), e2203150119. https://doi.org/10.1073/pnas.2203150119
[^2]: Mesnards, N. G. des, Hunter, D. S., Hjouji, Z. el, & Zaman, T. (2020). _Detecting Bots and Assessing Their Impact in Social Networks_ (arXiv:1810.12398). arXiv. https://doi.org/10.48550/arXiv.1810.12398
[^3]: Törnberg, P. (2022). How digital media drive affective polarization through partisan sorting. _Proceedings of the National Academy of Sciences_, _119_(42), e2207159119. https://doi.org/10.1073/pnas.2207159119
[^4]: 李纾, 刘欢, 白新文, 仁孝鹏, 郑蕊, 李金珍, 饶俪琳, & 王祚军. (2009). 汶川"5.12"地震中的"心理台风眼"效应. 科技导报, _27_(0903).]